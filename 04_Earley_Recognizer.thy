(*<*)
theory "04_Earley_Recognizer"
  imports
    "03_Fixpoint_Earley_Recognizer"
begin
(*>*)

chapter\<open>Earley Recognizer Implementation \label{chap:04}\<close>

section\<open>The Executable Algorithm \label{sec:alg}\<close>

text\<open>
In Chapter \ref{chapter:3} we proved correctness of a set-based, non-executable version of Earley's simplified recognizer algorithm. In this chapter we implement
an executable algorithm. But instead of re-proving soundness and completeness
for the executable algorithm, we follow the approach of Jones \cite{Jones:1972}. We refine our set-based
approach from Chapter \ref{chapter:3} to a \textit{functional} list-based implementation and prove subsumption in both
directions, or each item generated by the list-based approach is also generated by the set-based approach
which implies soundness of the executable algorithm, and vice versa which implies in turn completeness.
We extend the algorithm of Chapter \ref{chapter:3} in a second orthogonal way by already adding the necessary
information to construct parse trees. We only introduce and explain the needed data structures but refrain
from presenting any proofs in this chapter since constructing parse trees is the primary subject of Chapter \ref{chap:05}.

First we introduce a new data representation: instead of a set of Earley items we work with the data structure @{term bins}: a list of static length
(@{term "|\<omega>| + 1"}) containing in turn bins implemented as variable length lists of Earley \textit{entries}. An entry consists of an
Earley item and a new data type @{term pointer} representing conceptually an imperative pointer describing the origin of its accompanying item. Table \ref{tab:earley-items-pointers}
illustrates the bins for our running example. There are three possible reasons,
corresponding to the three basic operations, for the existence of an entry with Earley item $x$ in a specific bin $k$:

\begin{itemize}
  \item It was predicted. In that case we consider it created from thin air and do not need to
    track any additional information, thus the pointer is @{term Null}. For our example, bin
    $B_0$ contains the entry $S \rightarrow \, \bullet x, 0, 0; \bot$ consisting of the item $S \rightarrow \, \bullet x, 0, 0$ and a @{term Null} pointer denoted by $\bot$.
  \item It was scanned. Then there exists another Earley item $x'$ in the previous bin $k-1$
    from which this item was computed. Hence, we keep a predecessor pointer @{term "mbox0 (Pre pre)"}
    where @{term pre} is a natural number indicating the index of item $x'$ in bin $k-1$. Table \ref{tab:earley-items-pointers} contains
    the entry $S \rightarrow \, x \bullet, 2, 3; 1$ in bin $B_3$, the predecessor pointer is $1$ (we omit the @{term Pre} constructor for readability) since this item
    was created by the item $S \rightarrow \, \bullet x, 2, 2$ of the entry at index $1$ in $B_2$.
  \item It was completed. Note that an item might be completed in more than one way. In each case the
    item $x$ has a complete reduction item $y$ in the current bin and a predecessor item $x'$ in the
    origin bin of $y$. We track this information by at least one reduction pointer
    (@{term "PreRed (k', pre, red) reds"}) where $k'$, $pre$, and $red$ are respectively the origin index of
    the complete item $y$ or the bin of item $x'$, $pre$ is the index of $x'$ in bin $k'$, and $red$ is the index
    of $y$ in the current bin $k$. The list @{term reds} contains other valid reduction triples for this item.
    This is illustrated by the entry $S \rightarrow \, S + S \bullet, 0, 5; (4,1,0), (2,0,1)$ in bin $B_5$ of
    Table \ref{tab:earley-items-pointers}. We omit the @{term PreRed} and list constructors again for readability. This entry (without the second reduction triple) was first created due to the complete item $S \rightarrow \, x \bullet,4,5$
    at index $0$ in bin $B_5$ and the predecessor item $S \rightarrow \, S + \bullet S, 0, 4$ at index $1$ in bin $B_4$, but we can also create
    it by the complete item $S \rightarrow \, S + S \bullet,2,5$ at index $1$ in bin $B_5$ and the predecessor item
    $S \rightarrow \, S + \bullet S, 0, 2$ at index $0$ in bin $B_2$, or the two possible ways to derive
    the input $\omega = (x + x) + x$ and $\omega = x + (x + x)$.
\end{itemize}

Additionally, we define two useful abbreviations @{term items} and @{term pointers} that map a given
bin to the list of items respectively pointers it consists of.
\<close>

text\<open>
  \begin{table}[htpb]
    \caption[Earley items with pointers running example]{Earley items with pointers for the grammar @{term \<G>}: $S \rightarrow \, x$, $S \rightarrow \, S + S$}\label{tab:earley-items-pointers}
    \centering
    \begin{tabular}{| l | l | l | l |}
          & $B_0$                                       & $B_1$                                           & $B_2$                                     \\
      \midrule
        0 & $S \rightarrow \, \bullet x, 0, 0; \bot$     & $S \rightarrow \, x \bullet, 0, 1; 0$           & $S \rightarrow \, S + \bullet S, 0, 2; 1$   \\
        1 & $S \rightarrow \, \bullet S + S, 0, 0; \bot$ & $S \rightarrow \, S \bullet + S, 0, 1; (0,1,0)$ & $S \rightarrow \, \bullet x, 2, 2; \bot$       \\
        2 &                                           &                                                 & $S \rightarrow \, \bullet S + S, 2, 2; \bot$   \\

      \midrule

          & $B_3$                                               & $B_4$                                     & $B_5$                                                    \\
      \midrule
        0 & $S \rightarrow \, x \bullet, 2, 3; 1$           & $S \rightarrow \, S + \bullet S, 2, 4; 2$   & $S \rightarrow \, x \bullet, 4, 5; 2$                    \\
        1 & $S \rightarrow \, S + S \bullet, 0, 3; (2,0,0)$ & $S \rightarrow \, S + \bullet S, 0, 4; 3$   & $S \rightarrow \, S + S \bullet, 2, 5; (4,0,0)$          \\
        2 & $S \rightarrow \, S \bullet + S, 2, 3; (2,2,0)$ & $S \rightarrow \, \bullet x, 4, 4; \bot$       & $S \rightarrow \, S + S \bullet, 0, 5; (4,1,0), (2,0,1)$ \\
        3 & $S \rightarrow \, S \bullet + S, 0, 3; (0,1,1)$ & $S \rightarrow \, \bullet S + S, 4, 4; \bot$   & $S \rightarrow \, S \bullet + S, 4, 5; (4,3,0)$          \\
        4 &                                                 &                                             & $S \rightarrow \, S \bullet + S, 2, 5; (2,2,1)$          \\
        5 &                                                 &                                             & $S \rightarrow \, S \bullet + S, 0, 5; (0,1,2)$          \\
    \end{tabular}
  \end{table}
\<close>

datatype pointer =
  Null
| Pre nat \<comment>\<open>pre\<close>
| PreRed "nat \<times> nat \<times> nat" "(nat \<times> nat \<times> nat) list" \<comment>\<open>(k', pre, red) reds\<close>

datatype 'a entry =
  Entry (item : "'a item") (pointer : pointer)

type_synonym 'a bin = "'a entry list"
type_synonym 'a bins = "'a bin list"

definition items :: "'a bin \<Rightarrow> 'a item list" where
  "items b = map item b"

definition pointers :: "'a bin \<Rightarrow> pointer list" where
  "pointers b = map pointer b"

text\<open>
Next we implement list-based versions of the @{term Init}, @{term Scan}, @{term Predict}, and
@{term Complete} operations. Function @{term Init_list} creates a list of (@{term "|\<omega>| + 1"}) empty lists
or bins. Subsequently, it constructs an initial bin containing entries consisting of initial items for all the
production rules that have the start symbol on their left-hand sides, and finally it overwrites the
$0$-th bin with this initial bin.
\<close>

definition Init_list :: "'a cfg \<Rightarrow> 'a sentential \<Rightarrow> 'a bins" where
  "Init_list \<G> \<omega> \<equiv> 
    let bs = replicate ( |\<omega>| + 1) ([]) in
    let rs = filter (\<lambda>r. rule_head r = \<SS> \<G>) (\<RR> \<G>) in
    let b0 = map (\<lambda>r. (Entry (init_item r 0) Null)) rs in bs[0 := b0]"

text\<open>
Functions @{term Scan_list}, @{term Predict_list}, and @{term Complete_list} are defined analogously
to the definitions of @{term Scan}, @{term Predict}, and @{term Complete} and we only highlight noteworthy
differences. The set-based implementations take accumulated as arguments the index $k$ of the current
bin, the grammar @{term \<G>}, the input @{term \<omega>}, and the current set of Earley items $I$.
The list-based definitions are more specific. The $k$-th bin is no longer only conceptional and we replace the argument $I$ in the following ways: function
@{term Scan_list} takes as arguments the currently considered item $x$, its next \textit{terminal} symbol $a$ (as plain value and
not wrapped in an option) and the index @{term pre} of $x$ in the current bin $k$, and sets the predecessor pointer accordingly. Function @{term Predict_list}
only needs access to the next non-terminal symbol $N$ of $x$, and returns only entries with @{term Null} pointers. The implementation of @{term Complete_list}
is slightly more involved. It takes as arguments again $x$ and the index @{term red} of $x$ in the current bin $k$ (since $x$ is a
complete reduction item this time around), but also the complete bins @{term bs}, since
it needs to find all potential predecessor items as well as their indices in the origin bin of $x$ (see
@{term find_with_index}), and sets the reduction triples accordingly.
\<close>

definition Scan_list :: "nat \<Rightarrow> 'a sentential \<Rightarrow> 'a  \<Rightarrow> 'a item \<Rightarrow> nat \<Rightarrow> 'a entry list" where
  "Scan_list k \<omega> a x pre \<equiv>
    if \<omega>!k = a then
      let x' = inc_item x (k+1) in
      [Entry x' (Pre pre)]
    else []"

definition Predict_list :: "nat \<Rightarrow> 'a cfg \<Rightarrow> 'a \<Rightarrow> 'a entry list" where
  "Predict_list k \<G> N \<equiv>
    let rs = filter (\<lambda>r. rule_head r = N) (\<RR> \<G>) in
    map (\<lambda>r. (Entry (init_item r k) Null)) rs"

fun filter_with_index' :: "nat \<Rightarrow> ('a \<Rightarrow> bool) \<Rightarrow> 'a list \<Rightarrow> ('a \<times> nat) list" where
  "filter_with_index' _ _ [] = []"
| "filter_with_index' i P (x#xs) = (
    if P x then (x,i) # filter_with_index' (i+1) P xs
    else filter_with_index' (i+1) P xs)"

definition filter_with_index :: "('a \<Rightarrow> bool) \<Rightarrow> 'a list \<Rightarrow> ('a \<times> nat) list" where
  "filter_with_index P xs = filter_with_index' 0 P xs"

definition Complete_list :: "nat \<Rightarrow> 'a item \<Rightarrow> 'a bins \<Rightarrow> nat \<Rightarrow> 'a entry list" where
  "Complete_list k x bs red \<equiv>
    let orig = bs ! item_origin x in
    let is = filter_with_index (\<lambda>x'. next_symbol x' = Some (item_rule_head x)) (items orig) in
    map (\<lambda>(x', pre). (Entry (inc_item x' k) (PreRed (item_origin x, pre, red) []))) is"

text\<open>
In our data representation a bin is just a simple list but it implements a set. Hence, we need to make sure
that updating a bin (@{term bin_upd}) or inserting an additional entry into a bin maintains its set properties. Additionally, since it is possible to generate multiple
reduction pointers for the same item, we have to take care to update the pointer information accordingly, in particular merge reduction triples,
if the item of the entry to be inserted matches the item of an already present entry. Function @{term bin_upds} inserts
multiple entries into a specific bin. Finally, function @{term bins_upd} updates the $k$-th bin by inserting the given
list of entries using function @{term bin_upds}. Note that an alternative but equivalent implementation of @{term bin_upds} is @{term "fold bin_upd es b"}.
We primarily choose the explicit definition since it simplified some of the proofs, but overall the choice is
stylistic in nature.
\<close>

fun bin_upd :: "'a entry \<Rightarrow> 'a bin \<Rightarrow> 'a bin" where
  "bin_upd e' [] = [e']"
| "bin_upd e' (e#es) = (
    case (e', e) of
      (Entry x (PreRed px xs), Entry y (PreRed py ys)) \<Rightarrow> 
        if x = y then Entry x (PreRed py (px#xs@ys)) # es
        else e # bin_upd e' es
      | _ \<Rightarrow> 
        if item e' = item e then e # es
        else e # bin_upd e' es)"

fun bin_upds :: "'a entry list \<Rightarrow> 'a bin \<Rightarrow> 'a bin" where
  "bin_upds [] b = b"
| "bin_upds (e#es) b = bin_upds es (bin_upd e b)"

definition bins_upd :: "'a bins \<Rightarrow> nat \<Rightarrow> 'a entry list \<Rightarrow> 'a bins" where
  "bins_upd bs k es = bs[k := bin_upds es (bs!k)]"

text\<open>
The central piece for the list-based implementation is the function @{term Earley_bin_list'}. A
function call of the form @{term "Earley_bin_list' k \<G> \<omega> bs i"} completes the $k$-th bin starting from index $i$.
For the current item $x$ under consideration the function first computes the possible new entries depending on the next
symbol of $x$ which can either be some terminal symbol - we scan -, or non-terminal symbol - we predict -, or @{term None} - we complete.
It then updates the bins @{term bs} appropriately using the function @{term bins_upd}.
We have to define the function as a @{term partial_function},
since it might never terminate if it keeps appending newly generated items to the $k$-th bin it currently operates
on. We prove termination and highlight the relevant Isabelle specific details in Section \ref{sec:04-wellformedness}.
The function @{term Earley_bin_list} then fully completes the $k$-th bin, or starts its computation at index $0$, and thus corresponds in functionality to the function @{term Earley_bin} of Chapter \ref{chapter:3}.
\<close>

partial_function (tailrec) Earley_bin_list' :: "nat \<Rightarrow> 'a cfg \<Rightarrow> 'a sentential \<Rightarrow> 'a bins \<Rightarrow> nat \<Rightarrow> 'a bins" where
  "Earley_bin_list' k \<G> \<omega> bs i = (
    if i \<ge> |items (bs!k)| then bs
    else
      let x = items (bs!k) ! i in
      let bs' =
        case next_symbol x of
          Some a \<Rightarrow>
            if is_terminal \<G> a then
              if k < |\<omega>| then bins_upd bs (k+1) (Scan_list k \<omega> a x i)
              else bs
            else bins_upd bs k (Predict_list k \<G> a)
        | None \<Rightarrow> bins_upd bs k (Complete_list k x bs i)
      in Earley_bin_list' k \<G> \<omega> bs' (i+1))"

definition Earley_bin_list :: "nat \<Rightarrow> 'a cfg \<Rightarrow> 'a sentential \<Rightarrow> 'a bins \<Rightarrow> 'a bins" where
  "Earley_bin_list k \<G> \<omega> bs = Earley_bin_list' k \<G> \<omega> bs 0"

text\<open>
Finally, functions @{term Earley_list} and @{term \<E>arley_list} are structurally identical to functions
@{term Earley} respectively @{term \<E>arley} of Chapter \ref{chapter:3}, differing only in the type of the used operations and the
return type: bins or lists of items instead of set of items.

\newpage
\<close>

fun Earley_list :: "nat \<Rightarrow> 'a cfg \<Rightarrow> 'a sentential \<Rightarrow> 'a bins" where
  "Earley_list 0 \<G> \<omega> = Earley_bin_list 0 \<G> \<omega> (Init_list \<G> \<omega>)"
| "Earley_list (Suc n) \<G> \<omega> = Earley_bin_list (Suc n) \<G> \<omega> (Earley_list n \<G> \<omega>)"

definition \<E>arley_list :: "'a cfg \<Rightarrow> 'a sentential \<Rightarrow> 'a bins" where
  "\<E>arley_list \<G> \<omega> = Earley_list |\<omega>| \<G> \<omega>"

section \<open>A Word on Performance\<close>

text\<open>
Earley \cite{Earley:1970} implements his recognizer algorithm in the imperative programming paradigm and provides an informal
argument for the running time $\mathcal{O}(n^3)$ where @{term "n = |\<omega>|"}. In contrast, our implementation
is purely functional, and one might expect a quite significant decrease in performance. In this section we
provide an informal argument showing that, although we cannot quite achieve the time complexity of an imperative
implementation, we are 'only' one order of magnitude slower or the running time of our implementation is
$\mathcal{O}(n^4)$. Then we summarize Earley's imperative implementation approach and the additional steps
that are needed to achieve the desired running time. Additionally, we sketch a slightly different and more complicated functional
implementation that achieves a theoretical running time of $\mathcal{O}(n^3 \log{n})$, and highlight possible further
performance improvements. Finally, we discuss why we choose our particular implementation.

We state the running time of our implementation of the algorithm in terms of the length $n$ of the input @{term \<omega>},
and provide an informal argument that its running time is $\mathcal{O}(n^4)$.
Each bin $B_j$ ($0 \le j \le n$) contains only items of the form @{term "Item r b i j"}.
The number of possible production rules $r$, and possible bullet positions $b$ are both independent
of $n$ and can thus be considered (possible large) constants. The origin $i$ is bounded by $0 \le i \le j$ and thus
depends on $j$ which is in turn dependent on $n$. Thus, the number of items in each bin $B_j$ is overall $\mathcal{O}(n)$.

We also have @{term Init_list} $\in \mathcal{O}(n)$ since the function @{term replicate} takes time linear in the length of @{term \<omega>},
and functions @{term filter} and @{term map} operate at most on the size of the grammar @{term \<G>} or constant time.
We also know @{term Scan_list} $\in \mathcal{O}(n)$. The dominating term is surprisingly @{term "mbox0 (\<omega>!k)"}, since $0 \le k \le n$, and it computes
at most one new entry. Function @{term Predict_list} takes time in the the size of the grammar @{term \<G>},
due to the @{term filter} and @{term map} functions, or constant time, and computes at most @{term "|\<G>|"} new items.
Function @{term Complete_list} again takes linear time, since finding the origin bin of the given item
$x$ takes linear time, and functions @{term items}, @{term filter_with_index}, and @{term map}
operate on the origin bin which is - in the worst case - of linear size as argued in the previous paragraph. Consequently, the function also computes at most
$\mathcal{O}(n)$ new items. 

Updating a bin (@{term bin_upd}) with a single entry takes at most linear time, inserting $e$ new entries
(@{term bin_upds}) thus takes time $e \cdot \mathcal{O}(n)$, and hence function @{term bins_upd}
also runs in time $e \cdot \mathcal{O}(n)$. The analysis of function @{term Earley_bin_list'} is slightly
more involved. It computes the contents of a bin $B_j$, or it calls itself recursively at most $n$ times, since the number of items in any bin is $\mathcal{O}(n)$.
The time for one function execution is dominated by the time it takes to update the bins with the newly
created items whose number in turn depends on the operation we applied but is bounded in the worst case by $n$ during the @{term Complete_list} operation.
All the other operations of the function body run in at most linear time. Overall we have for the body of @{term Earley_bin_list'}: $\mathcal{O}(n) + e \cdot \mathcal{O}(n) = \mathcal{O}(n^2)$.
And thus @{term Earley_bin_list'} $\in \mathcal{O}(n^3)$. The same bound holds trivially for @{term Earley_bin_list}.
Since functions @{term \<E>arley_list} or @{term Earley_list} call @{term Earley_bin_list} once for each bin $B_j$ and $0 \le j \le n$,
the overall running time is $\mathcal{O}(n^4)$.

One might be tempted to think that the decrease in performance compared to an imperative implementation
is due to the fact that we are representing bins as functional lists and appending to and indexing into
bins which takes linear time and not constant time. This is not the case. Earley implements the algorithm as
follows. On the top-level bins are no longer a list but an array. Each bin is a singly-linked list, and
pointers are no longer represented by the type @{term pointer} but by actual pointers between entries.
The worst case running time of the algorithm is still $\mathcal{O}(n^4)$. The algorithm still iterates over
$n$ bins, traverses in the worst case $\mathcal{O}(n)$ items in each bin and for each item, the worst case
operation, completion, still generates $\mathcal{O}(n)$ new items that all have to be inserted into the
current bin which takes linear time for \textit{each} new item. To achieve the running time of $\mathcal{O}(n^3)$
we need to find a way to add a new item into a bin in constant time. In an imperative setting one obvious
way is to not only keep a singly-linked list of items and pointers but additionally a map. The keys are the items of the
list and the map stores as value for a specific item a pointer to itself or its position in the list. Insertion of a new item
into a bin then works as follows: if the item is already present in the map, we follow the pointer to the item and
update the parse tree pointers of the item in the list accordingly depending on the kind of item. Otherwise we just append the
item and its corresponding parse tree pointers to the list and insert the item and a pointer to its position
in the linked list into the map.

Sadly, this approach does not work in a functional setting. Appending an item to a list takes linear and
not constant time. But even if we preprend the new item onto the list there is another problem. We cannot
simply store pointers in the map that we can chase in constant time to the location of the item
in the list, but still have to store the index of the corresponding item. And consequently updating the pointer information
takes again linear time due to the indexing. One possible solution is to change one's point of view.
In the imperative approach the list serves two purposes: it represents the bin and is at the same time
a worklist for the algorithm. The map only optimizes performance. We can obtain a $\mathcal{O}(n^3 \log{n})$ functional
implementation if we consider the list only a worklist and the map (or its keys) the bin. We also need to adapt the
pointer datatype. Instead of wrapping indices representing predecessor or reduction items in the list,
a pointer should contain the actual items. E.g. a pointer is either @{term Null}, or @{term "Pre x'"}, or @{term "PreRed (x', y) xys"}
where $x'$ is respectively the predecessor item and $y$ is the complete reduction item.
Overall the running time for inserting a new item into a bin consists of prepending the item onto the worklist, or constant time,
and inserting the item into the map which can be done in logarithmic time. Thus, the overall running
time of this approach is $\mathcal{O}(n^3 \log{n})$.

Since we are already talking about performance, we highlight some of the more common performance improvements.
We can predict faster if we organize the grammar in a more efficient manner. Currently, the @{term Predict}
operation needs to pass through the whole grammar to find the alternatives for a specific non-terminal. The
first performance improvement is to group the production rules by their left-hand side non-terminals.
We can also complete more efficiently. The @{term Complete} operation scans through the origin bin of
an complete item, searching for items where the next symbol matches the rule head of the production rule
of the complete item. We can optimize this search by keeping an additional map from 'next symbol' non-terminals to
their corresponding items for each bin. Finally, as mentioned earlier, we omit implementing a lookahead terminal.
Note that, although these performance improvements might speed up the algorithm quite considerably, particularly
the lookahead terminal, none of them improve the worst case running time.

We decided against implementing the map-based functional approach with a running time of $\mathcal{O}(n^3 \log{n})$
and 'settle' for the current approach with a running time of $\mathcal{O}(n^4)$ due to two reasons.
The map-based functional approach is more complicated and the improvement of the running time, although
significant, still does not reach the optimum. If we optimize our approach only to achieve better performance,
we would like to achieve optimal performance, at least asymptotically. The current approach, appending items
to the list and using natural numbers as pointers, maps more easily to the imperative approach. And our original
intention was to refine the algorithm once more to an imperative version. This exceeded the scope of this thesis but is worthwhile future work.
\<close>

section \<open>Sets or Bins as Lists \label{sec:sets}\<close>

text\<open>
In this section we prove that the list representation of bins, in particular updating a bin or bins with the
functions @{term bin_upd}, @{term bin_upds}, and @{term bins_upd}, fulfills the required set semantics.
We define a function @{term bins} that accumulates all bins into one set of Earley items.
Note that a call of the form @{term "Earley_bin_list' k \<G> \<omega> bs i"} iterates through the entries of
the $k$-th bin or the current worklist in ascending order starting at index $i$. All items at indices
@{term "j \<ge> i"} are untouched and thus should already have been processed accordingly. We make two further definitions capturing
the set of items which should already be 'done'. The term @{term "bin_upto b i"} represents the items of a bin $b$
up to but not including the $i$-th index. Similarly, function @{term bins_upto} computes the set of
items consisting of the $k$-th bin up to but not including the $i$-th index and the items of all previous bins. 
\<close>

definition bins :: "'a bins \<Rightarrow> 'a items" where
  "bins bs = \<Union> { set (items (bs!k)) | k. k < |bs| }"

definition bin_upto :: "'a bin \<Rightarrow> nat \<Rightarrow> 'a items" where
  "bin_upto b i = { items b ! j | j. j < i \<and> j < |items b| }"

definition bins_upto :: "'a bins \<Rightarrow> nat \<Rightarrow> nat \<Rightarrow> 'a items" where
  "bins_upto bs k i = \<Union> { set (items (bs!l)) | l. l < k } \<union> bin_upto (bs!k) i"

text\<open>
The next six lemmas then proof the set semantics of updating one bin with one item (@{term bin_upd}),
multiple items (@{term bin_upds}), or updating a particular bin with multiple items (@{term bins_upd}).
The proofs are straightforward and respectively by induction on the bin $b$ for an arbitrary item $e$,
by induction on the items @{term es} to be inserted for an arbitrary bin $b$, or by definition of
@{term bin_upds} and @{term bins}, each time using previously proven lemmas in the appropriate proofs.
\<close>

lemma set_items_bin_upd:
  "set (items (bin_upd e b)) = set (items b) \<union> { item e }"
(*<*)
  sorry
(*>*)

text\<open>\<close>

lemma distinct_bin_upd:
  assumes "distinct (items b)"
  shows "distinct (items (bin_upd e b))"
(*<*)
  sorry
(*>*)

text\<open>\<close>

lemma set_items_bin_upds:
  "set (items (bin_upds es b)) = set (items b) \<union> set (items es)"
(*<*)
  sorry
(*>*)

text\<open>\<close>

lemma distinct_bin_upds:
  assumes "distinct (items b)"
  shows "distinct (items (bin_upds es b))"
(*<*)
  sorry
(*>*)

text\<open>\<close>

lemma bins_bins_upd:
  assumes "k < |bs|"
  shows "bins (bins_upd bs k es) = bins bs \<union> set (items es)"
(*<*)
  sorry
(*>*)

text\<open>\<close>

lemma distinct_bins_upd:
  assumes "distinct (items (bs!k))"
  shows "distinct (items (bins_upd bs k es ! k))"
(*<*)
  sorry
(*>*)

text\<open>
In our formalization we prove further basic lemmas about functions @{term bin_upd}, @{term bin_upds},
and @{term bins_upd}. In particular how updating bins changes the length of a bin, interacts with
indexing into a bin or does not change the ordering of the items in a bin. Furthermore, we prove
similar lemmas about functions @{term bin_upto} and @{term bins_upto} and their interplay with bin(s)
updates. We omit them for brevity.
\<close>

section \<open>Well-formedness and Termination \label{sec:04-wellformedness}\<close>

text\<open>
We also need to refine the notion of well-formed items to well-formed \textit{bin} items. An item is a well-formed bin
item for the $k$-th bin if it is a well-formed item and its end index coincides with $k$. We call
a bin well-formed if it only contains well-formed bin items and its items are distinct, and lift this
notion of well-formedness to the toplevel list of bins.
\<close>

definition wf_bin_item :: "'a cfg \<Rightarrow> 'a sentential \<Rightarrow> nat \<Rightarrow> 'a item \<Rightarrow> bool" where
  "wf_bin_item \<G> \<omega> k x \<equiv> wf_item \<G> \<omega> x \<and> item_end x = k"

definition wf_bin_items :: "'a cfg \<Rightarrow> 'a sentential \<Rightarrow> nat \<Rightarrow> 'a item list \<Rightarrow> bool" where
  "wf_bin_items \<G> \<omega> k xs \<equiv> \<forall>x \<in> set xs. wf_bin_item \<G> \<omega> k x"

definition wf_bin :: "'a cfg \<Rightarrow> 'a sentential \<Rightarrow> nat \<Rightarrow> 'a bin \<Rightarrow> bool" where
  "wf_bin \<G> \<omega> k b \<equiv> distinct (items b) \<and> wf_bin_items \<G> \<omega> k (items b)"

definition wf_bins :: "'a cfg \<Rightarrow> 'a list \<Rightarrow> 'a bins \<Rightarrow> bool" where
  "wf_bins \<G> \<omega> bs \<equiv> \<forall>k < |bs|. wf_bin \<G> \<omega> k (bs!k)"

text\<open>
Next we prove that inserting well-formed bin items maintains the well-formedness of a bin or bins.
The proofs are structurally analogous to those of Section \ref{sec:sets}.
\<close>

lemma wf_bin_bin_upd:
  assumes "wf_bin \<G> \<omega> k b"
  assumes "wf_bin_item \<G> \<omega> k (item e)"
  shows "wf_bin \<G> \<omega> k (bin_upd e b)"
(*<*)
  sorry
(*>*)

text\<open>\<close>

lemma wf_bin_bin_upds:
  assumes "wf_bin \<G> \<omega> k b"
  assumes "\<forall>x \<in> set (items es). wf_bin_item \<G> \<omega> k x"
  assumes "distinct (items es)"
  shows "wf_bin \<G> \<omega> k (bin_upds es b)"
(*<*)
  sorry
(*>*)

text\<open>\newpage\<close>

lemma wf_bins_bins_upd:
  assumes "wf_bins \<G> \<omega> bs"
  assumes "\<forall>x \<in> set (items es). wf_bin_item \<G> \<omega> k x"
  assumes "distinct (items es)"
  shows "wf_bins \<G> \<omega> (bins_upd bs k es)"
(*<*)
  sorry
(*>*)

text\<open>
At this point we would like to proof that function @{term Earley_bin_list'} also maintains the well-formedness of
the bins. But since it is a partial function we first need to take a short excursion into function definitions
in Isabelle.
Intuitively, a recursive function terminates if for every recursive call the size of its input strictly decreases.
And normally all functions defined in Isabelle must be total. But there are different ways to define a recursive function depending on the complexity of its termination:
(1) with the \textit{fun} keyword. Isabelle then tries to find a measure of the input that proves
termination. If successful we obtain an induction schema corresponding to the function definition.
(2) via the \textit{function} keyword. We then need to define and prove a suitable measure by hand.
(3) if the function is a partial function we need to define it with the keyword @{term partial_function}.
For tail-recursive functions the definition is straightforward, otherwise we have to wrap the
return type in an option to signal possible non-termination. But contrary to total functions we do
\textit{not} obtain the usual induction schema. To prove anything useful about a partial function we
have to define the set of inputs and a corresponding measure for which the function terminates and
subsequently prove an appropriate induction schema by hand.

As previously explained, in Section \ref{sec:alg} we defined the function @{term Earley_bin_list'} as a partial function
since a call of the form @{term "Earley_bin_list' k \<G> \<omega> bs i"} might never terminate if the function
keeps appending arbitrary new items to the $k$-th bin it currently operates on. But we know that the
newly generated items are not arbitrary but well-formed bin items. From lemma @{thm[source] finite_\<E>arley} of Chapter \ref{chapter:3} we also
know that the set of well-formed items is finite. Since we made sure to only add each item once to
a bin, the function @{term Earley_bin_list'} will eventually run out of new items to insert into
the bin it currently operates on and terminate.

In Isabelle we define the set of well-formed earley inputs as a set of quadruples consisting of the
index $k$ of the current bin, the grammar @{term \<G>}, the input @{term \<omega>}, and the bins @{term bs}.
Note that we not only require the bins to be well-formed but also suitable bounds on $k$ and the length
of the bins to make sure that we are not indexing outside the input or the bins as well as a well-formed
grammar to ensure we only generate well-formed bin items. We then define a suitable measure for the
termination of @{term "mbox0 (Earley_bin_list' k \<G> \<omega> bs i)"} that intuitively corresponds to the number of well-formed bin
items that are still possible to generate from index $i$ onwards. Finally, we prove an induction schema (@{term "earley induction"})
for the function by complete induction on the measure of the input. We omit showing the schema explicitly
since it is rather verbose. But intuitively it partitions the function into five cases: the base (@{term Base}) case where we have
run out of items to operate on and terminate; one case for completion (@{term Complete}) and prediction (@{term Predict}) each; and two cases for scanning
covering the normal (@{term Scan}) and the special case (@{term Pass}) where $k$ exceeds the length of the input.
\<close>

definition wf_earley_input :: "(nat \<times> 'a cfg \<times> 'a sentential \<times> 'a bins) set" where
  "wf_earley_input = { 
    (k, \<G>, \<omega>, bs) | k \<G> \<omega> bs.
      k \<le> |\<omega>| \<and> |bs| = |\<omega>| + 1 \<and>
      wf_\<G> \<G> \<and>
      wf_bins \<G> \<omega> bs }"

fun earley_measure :: "nat \<times> 'a cfg \<times> 'a sentential \<times> 'a bins \<Rightarrow> nat \<Rightarrow> nat" where
  "earley_measure (k, \<G>, \<omega>, bs) i = card { x | x. wf_bin_item \<G> \<omega> k x } - i"

text\<open>
Concluding this section, we prove that we maintain the well-formedness of the input for the function @{term Earley_bin_list'}.
The proof is by @{term "earley induction"}, lemma @{term wf_bins_bins_upd} and - straightforward and thus omitted - auxiliary lemmas
stating that the scanning, predicting and completing only generates well-formed bin items. The proofs
for functions @{term Earley_bin_list}, @{term Earley_list}, and @{term \<E>arley_list} are respectively
by definition, by induction on $k$ using additionally the fact that the initial bins are well-formed,
and once more by definition, each time using previously proven lemmas appropriately.
\<close>

lemma wf_earley_input_Earley_bin_list':
  assumes "(k, \<G>, \<omega>, bs) \<in> wf_earley_input" 
  shows "(k, \<G>, \<omega>, Earley_bin_list' k \<G> \<omega> bs i) \<in> wf_earley_input"
(*<*)
  sorry
(*>*)

text\<open>\<close>

lemma wf_earley_input_Earley_bin_list:
  assumes "(k, \<G>, \<omega>, bs) \<in> wf_earley_input" 
  shows "(k, \<G>, \<omega>, Earley_bin_list k \<G> \<omega> bs) \<in> wf_earley_input"
(*<*)
  sorry
(*>*)

text\<open>\<close>

lemma wf_earley_input_Earley_list:
  assumes "wf_\<G> \<G>"
  assumes "k \<le> |\<omega>|"
  shows "(k, \<G>, \<omega>, Earley_list k \<G> \<omega>) \<in> wf_earley_input"
(*<*)
  sorry
(*>*)

text\<open>\<close>

lemma wf_earley_input_\<E>arley_list:
  assumes "wf_\<G> \<G>"
  assumes "k \<le> |\<omega>|"
  shows "(k, \<G>, \<omega>, \<E>arley_list \<G> \<omega>) \<in> wf_earley_input"
(*<*)
  sorry
(*>*)

section \<open>Soundness\<close>

text\<open>
Now we are ready to prove subsumption in both directions. Since functions @{term Earley_list} and
@{term \<E>arley_list} are structurally identical to @{term Earley} respectively @{term \<E>arley}, the
main task for the next two sections is to show that function @{term Earley_bin_list} or @{term Earley_bin_list'}
computes the same items as the function @{term Earley_bin} that computes in turn the fixpoint of @{term Earley_step}.
We start with the easier direction: every item generated by the list-based approach is also present in the set-based
approach which implies soundness of the list-based algorithm. This is the 'easier' direction due to the fact that during execution of the body of
@{term "Earley_bin_list'"} we only consider a single item $x$ in bin $k$ at position $i$
and apply the appropriate operation. In contrast, one execution of function @{term Earley_step} applies the scan,
predict and complete operations for all previously computed items.

We start the soundness proof with three auxiliary lemmas proving subsumption of the three basic operations.
The proofs of lemmas @{term Scan_list_sub_Scan}, @{term Predict_list_sub_Predict}, and @{term Complete_list_sub_Complete}
are each straightforward by definition of the corresponding functions.
\<close>

lemma Scan_list_sub_Scan:
  assumes "wf_bins \<G> \<omega> bs"
  assumes "bins bs \<subseteq> I"
  assumes "k < |bs|"
  assumes "k < |\<omega>|"
  assumes "x \<in> set (items (bs!k))"
  assumes "next_symbol x = Some a"
  shows "set (items (Scan_list k \<omega> a x pre)) \<subseteq> Scan k \<omega> I"
(*<*)
  sorry
(*>*)

text\<open>\<close>

lemma Predict_list_sub_Predict:
  assumes "wf_bins \<G> \<omega> bs"
  assumes "bins bs \<subseteq> I"
  assumes "k < |bs|"
  assumes "x \<in> set (items (bs!k))"
  assumes "next_symbol x = Some N"
  shows "set (items (Predict_list k \<G> N)) \<subseteq> Predict k \<G> I"
(*<*)
  sorry
(*>*)

text\<open>\<close>

lemma Complete_list_sub_Complete:
  assumes "wf_bins \<G> \<omega> bs"
  assumes "bins bs \<subseteq> I"
  assumes "k < |bs|"
  assumes "x \<in> set (items (bs!k))"
  assumes "is_complete x"
  shows "set (items (Complete_list k x bs red)) \<subseteq> Complete k I"
(*<*)
  sorry
(*>*)

text\<open>
We then proof that all items generated by the function @{term Earley_bin_list'} are also present
in the set produced by the function @{term Earley_bin}. The proof is by @{term "earley induction"} for
an arbitrary set of items $I$. The cases @{term Base} and @{term Pass} are trivial. The other three
cases follow the same structure and we only highlight the @{term Complete} case. Lemma @{term Earley_bin_list_sub_Earley_bin}
follows from @{term Earley_bin_list'_sub_Earley_bin} by definition.
\<close>

lemma Earley_bin_list'_sub_Earley_bin:
  assumes "(k, \<G>, \<omega>, bs) \<in> wf_earley_input"
  assumes "bins bs \<subseteq> I"
  shows "bins (Earley_bin_list' k \<G> \<omega> bs i) \<subseteq> Earley_bin k \<G> \<omega> I"
(*<*)
  sorry
(*>*)

text\<open>
\begin{proof}

We are in the case @{term Complete}. Hence, the item $x$ in the $k$-th bin at index $i$ is complete
and the new bins @{term bs'} are @{term "bins_upd bs k (Complete_list k x bs i)"}. We can discharge
the assumptions of lemma @{term Complete_list_sub_Complete} by our assumptions of well-formed earley
input and @{term "bins bs \<subseteq> I"} and the additional assumption that we are in the @{term Complete} case,
and have @{term "bins bs' \<subseteq> I \<union> Complete k I"}. Since updating the bins maintains well-formedness of
the input we can use the induction hypothesis and obtain the fact
\begin{equation*}
  @{term "bins (Earley_bin_list' k \<G> \<omega> bs i) \<subseteq> Earley_bin k \<G> \<omega> (I \<union> Complete k I)"} \qquad (1)
\end{equation*}
We also know that @{term "I \<union> Complete k I \<subseteq> Earley_bin k \<G> \<omega> I"} since @{term Earley_bin} is the
fixpoint iteration of @{term Earley_step} that is in turn defined as @{term "I \<union> Scan k \<omega> I \<union> Complete k I \<union> mbox0 (Predict k \<G> I)"}.
Moreover we know that function @{term Earley_bin} is monotonic in the set it operates on. And thus we have
\begin{equation*}
  @{term "Earley_bin k \<G> \<omega> (I \<union> Complete k I) \<subseteq> Earley_bin k \<G> \<omega> (Earley_bin k \<G> \<omega> I)"} \qquad (2)
\end{equation*}
The statement to proof follows from (1), (2) and the fact that the function @{term Earley_bin} is
idempotent.

\end{proof}
\<close>

lemma Earley_bin_list_sub_Earley_bin:
  assumes "(k, \<G>, \<omega>, bs) \<in> wf_earley_input"
  assumes "bins bs \<subseteq> I"
  shows "bins (Earley_bin_list k \<G> \<omega> bs) \<subseteq> Earley_bin k \<G> \<omega> I"
(*<*)
  sorry
(*>*)

text\<open>
We prove lemma @{term Earley_list_sub_Earley} by induction on $k$ using the additional lemma
@{term Init_list_eq_Init}, that shows that the set of items created by the
@{term Init_list} and @{term Init} functions are identical,
and lemma @{term Earley_bin_list_sub_Earley_bin}. Lemma @{term \<E>arley_list_sub_\<E>arley}
follows by definition and concludes the first half of the subsumption proof that implies soundness
of the list-based implementation due to the soundness proof of the set of Earley items of Chapter \ref{chapter:3} (lemma @{term sound_\<E>arley}).
\<close>

lemma Init_list_eq_Init:
  shows "bins (Init_list \<G> \<omega>) = Init \<G>"
(*<*)
  sorry
(*>*)

text\<open>\<close>

lemma Earley_list_sub_Earley:
  assumes "wf_\<G> \<G>" "k \<le> |\<omega>|"
  shows "bins (Earley_list k \<G> \<omega>) \<subseteq> Earley k \<G> \<omega>"
(*<*)
  sorry
(*>*)

text\<open>\<close>

lemma \<E>arley_list_sub_\<E>arley:
  assumes "wf_\<G> \<G>" 
  shows "bins (\<E>arley_list \<G> \<omega>) \<subseteq> \<E>arley \<G> \<omega>"
(*<*)
  sorry
(*>*)

section \<open>Completeness\<close>

text\<open>
In this section we proof completeness of the list-based algorithm. The two main complications are
the following. The function @{term Earley_bin_list'} starts it computation at a specific index $i$ in the $k$-th
bin. In contrast, while completing the $k$-th bin, the set-based approach of Chapter \ref{chapter:3}
applies the function @{term Earley_step} in each iteration of the fixpoint computation to all items. Hence, we have to generalize the proofs such that all items at indices @{term "j \<le> i"} are
already 'done'. The second problem is more severe: as stated
the algorithm is incorrect, at least for some classes of grammars. In contrast to the fixpoint computation
of the set-based approach the list-based implementation imposes an order on the creation of items,
and sometimes order matters. Consider for example an item $A \rightarrow \, \bullet, i, j$,
or an epsilon-rule $A \rightarrow \, \epsilon$, that the list-based implementation encounters during
creation of bin $B_j$. Since the item is complete we apply the @{term Complete} operation. The algorithm first
determines the origin bin $i$ of the item which always coincides with $j$ for epsilon rules. Consequently,
we search the current bin $B_j$ for any items of the form $B \rightarrow \, \alpha \bullet A \beta, i', j$.
But bin $B_j$ is only partially constructed at this point in time. Hence, we might be missing some of
these items, either since they have not been predicted, or completed up to this point. Thus, if we apply
the complete operation to item $A \rightarrow \, \bullet, i, j$ immediately we might not generate all
items of the form $B \rightarrow \, \alpha A \bullet \beta, i', j$ and in turn not all items depending
on those items. In essence, we might be missing potential derivation paths.

There exist various approaches to deal with this problem. Aho \textit{et al} @{cite "Aho:1972"} take
a rather relaxed point of view and propose to keep interleaving the @{term Predict} and @{term Complete} operations
until no more new items are being generated. Earley @{cite "Earley:1970"} suggests to have the @{term Complete}
operation note that we actually need to move the bullet over the non-terminal $A$ when encountering
the item $A \rightarrow \, \bullet, i, j$, and taking this information into account in the subsequent
execution of the algorithm. Or, in essence, delaying the @{term Complete} operation for item $A \rightarrow \, \bullet, i, j$
until we are sure that we have encountered all items of the form $B \rightarrow \, \alpha \bullet A \beta, i', j$.
Earley suggests that the algorithm should keep an additional collection of non-terminals to look out for stored in an appropriate data structure.
Aycock \textit{et al} @{cite "Aycock:2002"} propose yet another approach based on a slight modification
of the @{term Predict} operation. Note that the problem during completion only arises if the non-terminal
$A$ is nullable, or there exists a derivation such that @{term "mbox0 (\<G> \<turnstile> A \<Rightarrow>\<^sup>* \<epsilon>)"}. The authors suggest the following
approach. Pre-compute nullable non-terminals using well-know approaches @{cite "Appel:2003"}@{cite "Fischer:2009"}.
If the algorithm encounters an item of the form $A \rightarrow \, \alpha \bullet B \beta, i, j$, predict
items $B \rightarrow \, \bullet \gamma, j, j$ for each rule $B \rightarrow \, \gamma$ of the grammar @{term \<G>}. But additionally
add the item $A \rightarrow \, \alpha B \bullet \beta, j, j$ if the non-terminal $B$ is nullable.

Interleaving prediction and completion until we generate no new items seems rather impractical in our opinion. Thus,
we only considered the approaches of Earley and Aycock \textit{et al}. Both ideas are straightforward
to implement in the context of a pure recognizer. But complications arise when we need to annotate the
items with the needed information to construct parse trees. For the approach of Earley it is no longer sufficient
to keep solely a list of nullable non-terminals to look out for but we need to maintain additional information
of the origin of these non-terminals to update the reduction and predecessor pointers accordingly. The
approach of Aycock \textit{et al} implies even more complications. For a pure recognizer they construct
an LR(0) automaton for the modified @{term Predict} operation, but for an Earley parser they introduce
a new type of automaton, a split-epsilon DFA, and also slightly rewrite the grammar into \textit{nihilist normal form}
to encode the necessary information to reconstruct derivations.

In the end, we decided against implementing any of the approaches above and follow the approach of
Jones @{cite "Jones:1972"}. We restrict the grammar. If we disallow any non-terminal to derive $\epsilon$,
the problem does not arise in the first place. Our justification for this approach is that it is by
far the simplest solution while still being practical and allowing a wide enough range of grammars to be supported.

Overall, our obligation for the remainder of the section is to prove that restricting the grammar
to not contain empty derivations ensures that the order of constructing items does not matter in the
end, and that the list-based approach covers the fixpoint computation of Chapter \ref{chapter:3}.
\<close>

definition nonempty_derives :: "'a cfg \<Rightarrow> bool" where
  "nonempty_derives \<G> \<equiv> \<forall>N \<in> set (\<NN> \<G>). \<not> (\<G> \<turnstile> [N] \<Rightarrow>\<^sup>* [])"

text\<open>
The core lemma is the following: if the grammar is well-formed and does not allow empty derivations, and a given item is well-formed,
sound and complete, then its item origin and item end cannot coincide, which implies that the origin of
the item is strictly smaller than the item end due to the well-formedness of the item. And consequently
there do not exist any items of the form $A \rightarrow \, \epsilon, i, j$ in any bin $B_j$.
\<close>

lemma impossible_complete_item:
  assumes "wf_\<G> \<G>"
  assumes "nonempty_derives \<G>"
  assumes "wf_item \<G> \<omega> x"
  assumes "sound_item \<G> \<omega> x"
  assumes "is_complete x" 
  assumes "item_origin x = k" "item_end x = k"
  shows False
(*<*)
  sorry
(*>*)

text\<open>
\begin{proof}

From assumptions @{term "sound_item \<G> \<omega> x"}, @{term "is_complete x"}, @{term "item_origin x = k"},
and @{term "mbox0 (item_end x = k)"} we have by definition of a sound and complete item that

\begin{equation*}
@{term "\<G> \<turnstile> item_rule_head x \<Rightarrow>\<^sup>* []"}
\end{equation*}

Since the grammar @{term \<G>} and the item $x$ are well-formed, we also know that the item rule head of $x$
is indeed a non-terminal. The proof concludes by assumption @{term "mbox0 (nonempty_derives \<G>)"} by definition.

\end{proof}
\<close>

text\<open>
Lemma @{term Complete_Un_absorb} then captures the idea that it does not matter for the @{term Complete} operation if
we add an additional item $z$ of the form $B \rightarrow \, \alpha \bullet A \beta, i, k$ to bin $B_k$
while constructing the $k$-th bin under the assumption of well-formedness and non-empty derivations.
\<close>

lemma Complete_Un_absorb:
  assumes "wf_\<G> \<G>"
  assumes "wf_items \<G> \<omega> I"
  assumes "sound_items \<G> \<omega> I"
  assumes "nonempty_derives \<G>"
  assumes "wf_item \<G> \<omega> z"
  assumes "item_end z = k"
  assumes "next_symbol z = Some A"
  shows "Complete k (I \<union> {z}) = Complete k I"
(*<*)
  sorry
(*>*)

text\<open>
\begin{proof}

Assume for the sake of contradiction that @{term "Complete k (I \<union> {z}) \<noteq> Complete k I"}. Then we
know that @{term "Complete k I \<subset> Complete k (I \<union> {z})"} since the @{term Complete} operation is
monotonic in $I$. Hence, there exist by definition of @{term Complete} items $x$, $x'$, and $y$
such that

\begin{equation*}
\begin{alignedat}{2}
  @{term "x \<in> Complete k (I \<union> z)"} \quad & (1) \quad @{term "x \<notin> Complete k I"} \quad & (2) \\
  @{term "x' \<in> bin (I \<union> {z}) (item_origin y)"} \quad & (3) \quad @{term "next_symbol x' = Some (item_rule_head y)"} \qquad & (4) \\
  @{term "y \<in> bin (I \<union> {z}) k"} \quad & (5) \quad @{term "is_complete y"} \quad & (6) \\
  @{term "x = inc_item x' k"} \quad & (7) & \\
\end{alignedat}
\end{equation*}

From assumptions (2-7) and the definition of @{term Complete} we need to consider two cases:

\begin{itemize}
  \item @{term "z = x'"}: Due to assumption @{term "item_end z = k"} and (3,5) we know that the item origin
    and end of item $y$ is $k$. Additionally, the item is sound and well-formed due to assumptions (5,6) and
    @{term "wf_items \<G> \<omega> I"}, @{term "wf_item \<G> \<omega> z"}, and @{term "sound_items \<G> \<omega> I"}, @{term "next_symbol z = Some A"}.
    Moreover, using assumptions @{term "wf_\<G> \<G>"} and @{term "mbox0 (nonempty_derives \<G>)"} and the fact that
    $y$ is complete (6), we can discharge the assumptions of lemma @{term impossible_complete_item} and
    arrive at a contradiction.
  \item @{term "z = y"}: Thus we know that $z$ must be complete since $y$ is complete by (6). But we
    also know that @{term "next_symbol z = Some A"}, a contradiction.
\end{itemize}

\end{proof}
\<close>

text\<open>
Next we prove that the items generated by function @{term Earley_bin_list'} cover the items
generated by a single @{term Earley_step}. Note the assumption @{term "Earley_step k \<G> \<omega> (mbox0 (bins_upto bs k i)) \<subseteq> bins bs"}
stating that all items up to index $i$ can already considered to be 'done' or applying the function @{term Earley_step}
to any of those items does not change the bins @{term bs}.
This assumption is necessary since a call of the form @{term "Earley_bin_list' k \<G> \<omega> bs i"} intuitively
skips the first $i$ items. The proof is by \textit{earley induction} and we only highlight the @{term Predict}
case where we need lemma @{term Complete_Un_absorb}. The other cases are similar in overall structure.
Lemma @{term Earley_step_sub_Earley_bin_list} then follows once more by definition.
\<close>

lemma Earley_step_sub_Earley_bin_list':
  assumes "(k, \<G>, \<omega>, bs) \<in> wf_earley_input"
  assumes "sound_items \<G> \<omega> (bins bs)"
  assumes "is_sentence \<G> \<omega>"
  assumes "nonempty_derives \<G>"
  assumes "Earley_step k \<G> \<omega> (bins_upto bs k i) \<subseteq> bins bs"
  shows "Earley_step k \<G> \<omega> (bins bs) \<subseteq> bins (Earley_bin_list' k \<G> \<omega> bs i)"
(*<*)
  sorry
(*>*)

text\<open>
\begin{proof}

We are only highlighting the @{term Predict} case. Hence, we are currently considering an item $x$
in the $k$-th bin at index $i$ whose next symbol is some non-terminal $N$. Let @{term bs'} denote
the updated bins or @{term "bins_upd bs k (Predict_list k \<G> N)"}. We know that the function @{term bins_upd}
maintains well-formedness and soundness of the items, but to apply our induction hypothesis
we need to proof one additional statement:

\begin{equation*}
@{term "Earley_step k \<G> \<omega> (bins_upto bs' k (i+1)) \<subseteq> bins bs'"}
\end{equation*}

Since @{term Earley_step} is defined as the union of the basic three operations we split this proof
into these three cases:

\begin{itemize}

  \item @{term "Scan k \<omega> (bins_upto bs' k (i+1)) \<subseteq> bins bs'"}:
    \begin{equation*}
    \begin{alignedat}{2}
      & @{term "Scan k \<omega> (bins_upto bs' k (i+1))"} & \\
      & \qquad = @{term "Scan k \<omega> (bins_upto bs' k i \<union> { items (bs'!k)!i })"} \quad & (1) \\
      & \qquad = @{term "Scan k \<omega> (bins_upto bs k i \<union> {x})"} \quad & (2) \\
      & \qquad \subseteq @{term "bins bs \<union> Scan k \<omega> {x}"} \quad & (3) \\
      & \qquad = @{term "bins bs"} \quad & (4) \\
      & \qquad \subseteq @{term "bins bs'"} & \quad (5)
    \end{alignedat}
    \end{equation*}

    (1) by definition of @{term bins_upto}.
    (2) function @{term bins_upd} does not change the order of the items of bin $k$ upto and including index $i$.
    (3) function @{term Scan} distributes over set union, assumption
      @{term "Earley_step k \<G> \<omega> (bins_upto bs k i) \<subseteq> bins bs"} and the definition of @{term Earley_step}.
    (4) the next symbol of $x$ is the non-terminal $N$ and thus the @{term Scan} operation yield an empty set.
    (5) the set semantics of function @{term bins_upd}.

  \item @{term "Predict k \<G> (bins_upto bs' k (i+1)) \<subseteq> bins bs'"}
    \begin{equation*}
    \begin{alignedat}{2}
      & @{term "Predict k \<G> (bins_upto bs' k (i+1))"} & \\
      & \qquad =  @{term "Predict k \<G> (bins_upto bs' k i \<union> { items (bs'!k)!i })"} \quad & (1) \\
      & \qquad = @{term "Predict k \<G> (bins_upto bs k i \<union> {x})"} \quad & (2) \\
      & \qquad \subseteq @{term "bins bs \<union> Predict k \<G> {x}"} \quad & (3) \\
      & \qquad = @{term "bins bs \<union> set (items (Predict_list k \<G> N))"} \quad & (4) \\
      & \qquad \subseteq @{term "bins bs'"} & \quad (5)
    \end{alignedat}
    \end{equation*}

    (1-3,5) are identical to the first case.
    (4) the next symbol of $x$ is the non-terminal $N$ and thus the list-based implementation yields the
      same items as the set-based implementation.

  \item @{term "Complete k (bins_upto bs' k (i+1)) \<subseteq> bins bs'"}
    \begin{equation*}
    \begin{alignedat}{2}
      & @{term "Complete k (bins_upto bs' k (i+1))"} & \\
      & \qquad = @{term "Complete k (bins_upto bs' k i \<union> { items (bs'!k)!i })"} \quad & (1) \\
      & \qquad = @{term "Complete k (bins_upto bs k i \<union> {x})"} \quad & (2) \\
      & \qquad = @{term "Complete k (bins_upto bs k i)"} \quad & (3) \\
      & \qquad \subseteq @{term "bins bs"} \quad & (4) \\
      & \qquad \subseteq @{term "bins bs'"} & \quad (5)
    \end{alignedat}
    \end{equation*}

    (1-2,5) are identical to the first case.
    (3) by lemma @{term Complete_Un_absorb} using the well-formedness, soundness, non-empty derivation assumptions
      and the fact that the item $x$ is in the $k$-th bin and its next symbol is the non-terminal $N$.
    (4) by assumption @{term "Earley_step k \<G> \<omega> (bins_upto bs k i) \<subseteq> bins bs"} and the definition of @{term Earley_step}.

\end{itemize}

\end{proof}

\newpage
\<close>

lemma Earley_step_sub_Earley_bin_list:
  assumes "(k, \<G>, \<omega>, bs) \<in> wf_earley_input"
  assumes "sound_items \<G> \<omega> (bins bs)"
  assumes "is_sentence \<G> \<omega>"
  assumes "nonempty_derives \<G>"
  assumes "Earley_step k \<G> \<omega> (bins_upto bs k 0) \<subseteq> bins bs"
  shows "Earley_step k \<G> \<omega> (bins bs) \<subseteq> bins (Earley_bin_list k \<G> \<omega> bs)"
(*<*)
  sorry
(*>*)

text\<open>
We have proven that the items generated by the execution of the list-based approach covers
\textit{one} single step of the set-based approach. Our next objective is to generalize this statement
to the whole fixpoint computation, or an arbitrary number of steps. We need two, albeit small, quite
technical lemmas, proving that the function @{term Earley_bin_list} is idempotent. This follows from the
next lemma which states that when we execute the function @{term Earley_bin_list'} two times, passing as
the argument for the bins of the second round the result of the first round, and are starting the execution from
possibly different initial indices the result of the smaller index prevails. The intuition is clear: if
we run through the worklist starting from index $i \le j$, starting a second time from index $j$ does not
yield any new items, since we already covered all items of the second execution in the first turn and order
does not matter due to the assumption of non-empty derivations. The proof is by \textit{earley induction} for arbitrary $j$ and once more utilizes lemma
@{term impossible_complete_item}, we omit showing any details.
\<close>

lemma Earley_bin_list'_idem:
  assumes "(k, \<G>, \<omega>, bs) \<in> wf_earley_input"
  assumes "sound_items \<G> \<omega> (bins bs)"
  assumes "nonempty_derives \<G>"
  assumes "i \<le> j"
  shows "bins (Earley_bin_list' k \<G> \<omega> (Earley_bin_list' k \<G> \<omega> bs i) j) = bins (Earley_bin_list' k \<G> \<omega> bs i)"
(*<*)
  sorry
(*>*)

text\<open>\<close>

lemma Earley_bin_list_idem:
  assumes "(k, \<G>, \<omega>, bs) \<in> wf_earley_input"
  assumes "sound_items \<G> \<omega> (bins bs)"
  assumes "nonempty_derives \<G>"
  shows "bins (Earley_bin_list k \<G> \<omega> (Earley_bin_list k \<G> \<omega> bs)) = bins (Earley_bin_list k \<G> \<omega> bs)"
(*<*)
  sorry
(*>*)

text\<open>
Lemma @{term Earley_bin_sub_Earley_bin_list} concludes the subsumption proof for a single bin.
Since the function @{term Earley_bin} is defined as the fixpoint of the function
@{term Earley_step} and the fact that @{term "x \<in> limit f X \<equiv> \<exists>n. x \<in> funpower f n X"} the core
proof is by induction on the computation of @{term funpower} \newpage.
\<close>

lemma Earley_bin_sub_Earley_bin_list:
  assumes "(k, \<G>, \<omega>, bs) \<in> wf_earley_input"
  assumes "sound_items \<G> \<omega> (bins bs)"
  assumes "is_sentence \<G> \<omega>"
  assumes "nonempty_derives \<G>"
  assumes "Earley_step k \<G> \<omega> (bins_upto bs k 0) \<subseteq> bins bs"
  shows "Earley_bin k \<G> \<omega> (bins bs) \<subseteq> bins (Earley_bin_list k \<G> \<omega> bs)"
(*<*)
  sorry
(*>*)

text\<open>
\begin{proof}

The goal is @{term "funpower (Earley_step k \<G> \<omega>) (Suc n) (bins bs) \<subseteq> bins (Earley_bin_list k \<G> \<omega> bs)"}.

For the base case we have @{term "funpower (Earley_step k \<G> \<omega>) 0 (bins bs) = bins bs"}. And we conclude
the proof due to the fact that the function @{term Earley_bin_list} is monotonic in the bins.

For the induction step we first need to proof a necessary precondition for our induction hypothesis:

\begin{equation*}
  \begin{alignedat}{2}
    & @{term "Earley_step k \<G> \<omega> (bins_upto (Earley_bin_list k \<G> \<omega> bs) k 0)"} & \\
    & \qquad = @{term "Earley_step k \<G> \<omega> (bins_upto bs k 0)"} \quad & (1) \\
    & \qquad \subseteq @{term "bins bs"} \quad & (2) \\
    & \qquad \subseteq @{term "bins (Earley_bin_list k \<G> \<omega> bs)"} \quad & (3) \\
  \end{alignedat}
\end{equation*}

(1) @{term "Earley_bin_list k \<G> \<omega> bs"} does not change the contents of any bins $B_j$ where @{term "j < k"}
  by definition of @{term bins_upto}.
(2) by assumption.
(3) function @{term Earley_bin_list} only adds to the bins.

\begin{equation*}
  \begin{alignedat}{2}
    & @{term "funpower (Earley_step k \<G> \<omega>) (Suc n) (bins bs)"} & \\
    & \qquad = @{term "Earley_step k \<G> \<omega> (funpower (Earley_step k \<G> \<omega>) n (bins bs))"} \quad & (1) \\
    & \qquad \subseteq @{term "Earley_step k \<G> \<omega> (bins (Earley_bin_list k \<G> \<omega> bs))"} \quad & (2) \\
    & \qquad \subseteq @{term "bins (Earley_bin_list k \<G> \<omega> (Earley_bin_list k \<G> \<omega> bs))"} \quad & (3) \\
    & \qquad \subseteq @{term "bins (Earley_bin_list k \<G> \<omega> bs)"} \quad & (4)
\end{alignedat}
\end{equation*}

(1) by definition of @{term funpower}.
(2) by induction hypothesis and fact that the function @{term Earley_step} is monotonic in the set of items.
(3) by lemma @{term Earley_step_sub_Earley_bin_list} using well-formedness, soundness, non-empty derivations assumptions.
(4) by lemma @{term Earley_bin_list_idem} using once more the soundness and non-empty derivation assumptions.

\end{proof}
\newpage
\<close>

text\<open>
We finish the subsumption proof with lemmas @{term "Earley_sub_Earley_list"} and @{term "\<E>arley_sub_\<E>arley_list"}.
The proofs are respectively by induction on $k$ using lemmas @{term Init_list_eq_Init} and @{term Earley_bin_sub_Earley_bin_list},
and once more by definition using the previous lemma.
\<close>

lemma Earley_sub_Earley_list:
  assumes "wf_\<G> \<G>"
  assumes "is_sentence \<G> \<omega>"
  assumes "nonempty_derives \<G>"
  assumes "k \<le> |\<omega>|"
  shows "Earley k \<G> \<omega> \<subseteq> bins (Earley_list k \<G> \<omega>)"
(*<*)
  sorry
(*>*)

text\<open>\<close>

lemma \<E>arley_sub_\<E>arley_list:
  assumes "wf_\<G> \<G>"
  assumes "is_sentence \<G> \<omega>"
  assumes "nonempty_derives \<G>"
  shows "\<E>arley \<G> \<omega> \<subseteq> bins (\<E>arley_list \<G> \<omega>)"
(*<*)
  sorry
(*>*)

section \<open>Correctness\<close>

text\<open>
We conclude the chapter presenting the final correctness theorem stating that there exists
a finished item in the bins generated by the list-based implementation if and only if there
exists a derivation of the input from the start symbol of the grammar. The proof is by lemmas
@{thm[source] correctness_\<E>arley}, @{thm[source] \<E>arley_list_sub_\<E>arley}, and @{thm[source] \<E>arley_sub_\<E>arley_list}.
\<close>

theorem correctness_\<E>arley_list:
  assumes "wf_\<G> \<G>"
  assumes "is_sentence \<G> \<omega>"
  assumes "nonempty_derives \<G>"
  shows "recognizing (bins (\<E>arley_list \<G> \<omega>)) \<G> \<omega> \<longleftrightarrow> \<G> \<turnstile> [\<SS> \<G>] \<Rightarrow>\<^sup>* \<omega>"
(*<*)
  sorry
(*>*)

(*<*)
end
(*>*)