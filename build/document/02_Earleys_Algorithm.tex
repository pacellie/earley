%
\begin{isabellebody}%
\setisabellecontext{{\isadigit{0}}{\isadigit{2}}{\isacharunderscore}{\kern0pt}Earleys{\isacharunderscore}{\kern0pt}Algorithm}%
%
\isadelimtheory
%
\endisadelimtheory
%
\isatagtheory
%
\endisatagtheory
{\isafoldtheory}%
%
\isadelimtheory
%
\endisadelimtheory
%
\isadelimdocument
%
\endisadelimdocument
%
\isatagdocument
%
\isamarkupchapter{Earley's Algorithm%
}
\isamarkuptrue%
%
\isamarkupsection{Draft%
}
\isamarkuptrue%
%
\endisatagdocument
{\isafolddocument}%
%
\isadelimdocument
%
\endisadelimdocument
%
\begin{isamarkuptext}%
\begin{itemize}
    \item Introduce the Earley recognizer in the abstract set form \\
    \item Introduce the running example S -> x | S + S for input x + x + x \\
    \item Illustrate the complete bins generated by the example \\
    \item Illustrate Initial S -> .alpha,0,0, Scan A -> alpha.abeta,i,j | A -> alpha.beta,i,j+1,
      Predict A -> alpha.Bbeta,i,j and B -> gamma | B -> .gamma,j,j,
      Complete A -> alpha.Bbeta,i,j and B -> gamma.,j,k | A -> alphaB.beta,i,k \\
    \item Define goal: A -> alpha.beta,i,j iff A =>* s[i..j)beta which implies S -> alpha.,0,n+1 iff S =>* s \\
  \end{itemize}%
\end{isamarkuptext}\isamarkuptrue%
%
\isadelimdocument
%
\endisadelimdocument
%
\isatagdocument
%
\isamarkupsection{Earley Recognizer%
}
\isamarkuptrue%
%
\endisatagdocument
{\isafolddocument}%
%
\isadelimdocument
%
\endisadelimdocument
%
\begin{isamarkuptext}%
We present a slightly simplified version of Earley's original recognizer algorithm \cite{Earley:1970}.
Throughout this thesis we will work with a running example. The grammar is a tiny excerpt of a toy
arithmetic expression grammar: \isa{{\isasymG}} $::= S \rightarrow \, x \, \vert \, S \rightarrow \, S + S$ and
the input is \isa{{\isasymomega}} $= x + x + x$. Given a grammar \isa{{\isasymG}} a recognizer for the language \isa{{\isasymL}{\isacharunderscore}{\kern0pt}{\isasymG}} accepts the input \isa{{\isasymomega}}
if and only if there exists a derivation of \isa{{\isasymomega}} originating from start symbol $S$ of \isa{{\isasymG}}.

Intuitively, Earley's recognizer works in principle like a top-down parser carrying along all possible
parses simultaneously in an efficient manner.
In detail, the algorithm works as follows: it scans the input \isa{{\isasymomega}} $=a_0,\dots,a_n$, constructing
$n+1$ bins $B_i$ which are sets of Earley items. An inital bin $B_0$ and one bin $B_{i+1}$ for
each symbol $a_i$ of the input.
In generell, an Earley item $A \rightarrow \, \alpha \bullet \beta, i, j$ consists of four parts: a production rule of the grammar which we are currently
scanning, a bullet signalling how much of the production's right-hand side we have recognized so far,
an origin $i$ describing the position of \isa{{\isasymomega}} where we started scanning, and an end $j$ indicating
the position  of \isa{{\isasymomega}} we are currently considering next for the remaining right-hand side of the production rule.
For example, the bin $B_4$ contains, for our arithmetic expression grammar, the item $S \rightarrow \, S + \bullet S, 2, 4$.
We are scanning the rule $S \rightarrow \, S + S$, have recognized the substring from $2$ to $4$ (the first index being
inclusive the second one exclusive) of \isa{{\isasymomega}} by $\alpha = S +$, and are trying to scan $\beta = S$ from position 4 in \omega. 

We say an item is part of bin $B_j$ if it's end is the index $j$.%
\end{isamarkuptext}\isamarkuptrue%
%
\begin{isamarkuptext}%
EARLEY:

In general, we operate on a state set Si as follows:
we process the states in the set in order, performing one of three operatins on each one depending on the form
of the state. These operations may add more states to Si and may also put states in a new state set Si+1. We
describe the operations by example: ... The predictor operation is applicable to a state when there is a nonterminal
to  the right of the dot. It causes us to add one new state to Si for each alternative of that nonterminal.
We put the dot at the beginning of the production in each new state, since we have not scanned any of its symbols yet.
The pointer is set to i, since the state was created in Si. Thus the predictor adds to Si all the productions
which might generate substrings beginning at Xi+1. The scanner is applicable in case there is a terminal to the right
of the dot. The scanner compares that symbol with Xi+1 and if they match, it adds the state to Si+1 with the dot
moved over one in the state to indicate that that terminal symbol has been scanned. If we finish processing Si and
Si+1 remains empty an error has occurred in the input string. Otherwise, we start to process Si+1.
The completer is applicable to a state if its dot is at the end of its production. It goes back to the state set
indicated by its pointer and adds all states from this state set which have the dot in front of its nonterminal.
It then moves over the dot. Intuitively, the origin state set is the state set we were in when we went looking
for that nonterminal. We have now found it, so we go back to all the states which caused us to look for it, and move
the dot over in these states to show that it has been successfully scanned. If the algorithm ever produces an Si+1
consisting of the single state S -> alpha dot, 0, n, then the sentence is part of the grammar.

AYCOCK:

An Earley set $S_i$ is computed from an initial set of Earley items in $S_i$ and $S_{i+1}$ is initialized, by
applying the followingn three steps to the items in $S_i$ until no more can be added. $\dots$
An item is added to a set only if it is not in the set already. The initial set $S_0$ contains the items $\dots$
to begin with. If the final set contains the item $\dots$ then the input is accepted.

We have not used a lookahead in this description of Earley parsing since it's primary purpose is to
increase the efficieny of the Earley parser on a large class of grammars (REFERENCE).%
\end{isamarkuptext}\isamarkuptrue%
%
\begin{isamarkuptext}%
\begin{figure}[htpb]
    \centering

    \begin{mathpar}
      \inferrule [Init]
      {\\}
      {$S \rightarrow \, \bullet\alpha, 0, 0$}
  
      \inferrule [Scan]
      {$A \rightarrow \, \alpha \bullet a \beta, i, j$ \\ $\isa{{\isasymomega}}[j] = a$}
      {$A \rightarrow \, \alpha a \bullet \beta, i, j+1$}
  
      \inferrule [Predict]
      {$A \rightarrow \, \alpha \bullet B \beta, i, j$ \\ $B \rightarrow \, \gamma \, \in \, \isa{{\isasymG}}$}
      {$B \rightarrow \, \bullet \gamma, j, j$}
  
      \inferrule [Complete]
      {$A \rightarrow \, \alpha \bullet B \beta, i, j$ \\ $B \rightarrow \, \gamma \bullet, j, k$}
      {$A \rightarrow \, \alpha B \bullet \beta, i, k$}
    \end{mathpar}
    \caption[Earley inference rules]{Earley inference rules}\label{fig:earley-inference-rules}
  \end{figure}%
\end{isamarkuptext}\isamarkuptrue%
%
\begin{isamarkuptext}%
$$A \rightarrow \, \alpha \bullet \beta, i, j \,\,\, \textrm{iff} \,\,\, A \, \xRightarrow{\ast} \, \isa{{\isasymomega}}[i..j)$$
$$S \rightarrow \, \alpha \bullet, 0, \isa{{\isacharbar}{\kern0pt}{\isasymomega}{\isacharbar}{\kern0pt}\ {\isacharplus}{\kern0pt}\ {\isadigit{1}}} \,\,\, \textrm{iff} \,\,\, S \, \xRightarrow{\ast} \, \isa{{\isasymomega}}$$%
\end{isamarkuptext}\isamarkuptrue%
%
\begin{isamarkuptext}%
$S \rightarrow \, x$ $S \rightarrow \, S + S$%
\end{isamarkuptext}\isamarkuptrue%
%
\begin{isamarkuptext}%
\begin{table}[htpb]
    \caption[Earley items running example]{Earley items for the grammar \isa{{\isasymG}}: $S \rightarrow \, x$, $S \rightarrow \, S + S$}\label{tab:earley-items}
    \centering
    \begin{tabular}{| l | l | l |}
        $B_0$                                   & $B_1$                                    & $B_2$                                \\
      \midrule
        $S \rightarrow \, \bullet x, 0, 0$      & $S \rightarrow \, x \bullet, 0, 1$     & $S \rightarrow \, S + \bullet S, 0, 2$ \\
        $S \rightarrow \, \bullet S + S, 0 , 0$ & $S \rightarrow \, S \bullet + S, 0, 1$ & $S \rightarrow \, \bullet x, 2, 2$     \\
                                                &                                        & $S \rightarrow \, \bullet S + S, 2, 2$ \\

      \midrule

        $B_3$                                  & $B_4$                                    & $B_5$                                \\
      \midrule
        $S \rightarrow \, x \bullet, 2, 3$     & $S \rightarrow \, S + \bullet S, 2, 4$ & $S \rightarrow \, x \bullet, 4, 5$     \\
        $S \rightarrow \, S + S \bullet, 0, 3$ & $S \rightarrow \, S + \bullet S, 0, 4$ & $S \rightarrow \, S + S \bullet, 2, 5$ \\
        $S \rightarrow \, S \bullet + S, 2, 3$ & $S \rightarrow \, \bullet x, 4, 4$     & $S \rightarrow \, S + S \bullet, 0, 5$ \\
        $S \rightarrow \, S \bullet + S, 0, 3$ & $S \rightarrow \, \bullet S + S, 4, 4$ & $S \rightarrow \, S \bullet + S, 4, 5$ \\
                                               &                                        & $S \rightarrow \, S \bullet + S, 2, 5$ \\
                                               &                                        & $S \rightarrow \, S \bullet + S, 0, 5$ \\
    \end{tabular}
  \end{table}%
\end{isamarkuptext}\isamarkuptrue%
%
\isadelimtheory
%
\endisadelimtheory
%
\isatagtheory
%
\endisatagtheory
{\isafoldtheory}%
%
\isadelimtheory
%
\endisadelimtheory
%
\end{isabellebody}%
\endinput
%:%file=02_Earleys_Algorithm.tex%:%
%:%24=8%:%
%:%28=10%:%
%:%40=13%:%
%:%41=14%:%
%:%42=15%:%
%:%43=16%:%
%:%44=17%:%
%:%45=18%:%
%:%46=19%:%
%:%47=20%:%
%:%48=21%:%
%:%57=24%:%
%:%69=27%:%
%:%70=28%:%
%:%71=29%:%
%:%72=30%:%
%:%73=31%:%
%:%74=32%:%
%:%75=33%:%
%:%76=34%:%
%:%77=35%:%
%:%78=36%:%
%:%79=37%:%
%:%80=38%:%
%:%81=39%:%
%:%82=40%:%
%:%83=41%:%
%:%84=42%:%
%:%85=43%:%
%:%86=44%:%
%:%87=45%:%
%:%88=46%:%
%:%92=51%:%
%:%93=52%:%
%:%94=53%:%
%:%95=54%:%
%:%96=55%:%
%:%97=56%:%
%:%98=57%:%
%:%99=58%:%
%:%100=59%:%
%:%101=60%:%
%:%102=61%:%
%:%103=62%:%
%:%104=63%:%
%:%105=64%:%
%:%106=65%:%
%:%107=66%:%
%:%108=67%:%
%:%109=68%:%
%:%110=69%:%
%:%111=70%:%
%:%112=71%:%
%:%113=72%:%
%:%114=73%:%
%:%115=74%:%
%:%116=75%:%
%:%117=76%:%
%:%118=77%:%
%:%119=78%:%
%:%120=79%:%
%:%124=83%:%
%:%125=84%:%
%:%126=85%:%
%:%127=86%:%
%:%128=87%:%
%:%129=88%:%
%:%130=89%:%
%:%131=90%:%
%:%132=91%:%
%:%133=92%:%
%:%134=93%:%
%:%135=94%:%
%:%136=95%:%
%:%137=96%:%
%:%138=97%:%
%:%139=98%:%
%:%140=99%:%
%:%141=100%:%
%:%142=101%:%
%:%143=102%:%
%:%144=103%:%
%:%145=104%:%
%:%149=108%:%
%:%150=109%:%
%:%154=112%:%
%:%158=115%:%
%:%159=116%:%
%:%160=117%:%
%:%161=118%:%
%:%162=119%:%
%:%163=120%:%
%:%164=121%:%
%:%165=122%:%
%:%166=123%:%
%:%167=124%:%
%:%168=125%:%
%:%169=126%:%
%:%170=127%:%
%:%171=128%:%
%:%172=129%:%
%:%173=130%:%
%:%174=131%:%
%:%175=132%:%
%:%176=133%:%
%:%177=134%:%
%:%178=135%:%
%:%179=136%:%
